---
title: "STAT 380 Final Project"
author: "Adithya Sadagopan, Tommy Lee, Alex Piechucki, and Vyacheslav Hlushko"
date: "2023-12-04"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter
```{r  message=FALSE, warning=FALSE}
library(tidyverse)
library(randomForest)
```

### Read in Data
```{r}
maps <- read.csv(file = "data/CODMaps.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL)
p1 <- read.csv(file = "data/CODGames_p1_380.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL,
                 na.strings = c("", "NA"))
p2 <- read.csv(file = "data/CODGames_p2_380.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL,
                 na.strings = c("", "NA"))
gmodes <- read.csv(file = "data/CODGameModes.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL)
```


## Final Project

### Part 1: Which maps are the most likely to win the map vote? 

- Background Info: Prior to each online match, players in the game lobby are presented with two options for the battlefield of the upcoming game (`Map1` and `Map2`). The players have the option to vote and the resulting vote is recorded in the `MapVote` column. The winning map is listed in the `Choice` column. In the event of a tie vote, the map listed in `Map1` is chosen. (Games for which the player entered the lobby after the vote has taken place have no information in `Map1` and `Map2` but have the winning map presented in `Choice`.)

- Notes: To answer this question, write a paragraph discussing how you plan to answer this question. Be sure to address the data quality issues mentioned below. Then, write code and answer the question. As part of your solution, you should calculate the proportion of times that each map was listed as a candidate (Map1 or Map2) and earned more votes than the other candidate. As part of this, you should consider whether a given map won the vote by getting more votes than the other option or was selected since it was `Map1` and the vote was a tie. You should also include a visualization of the results. There are some data quality issues (such as misspelled map names and extra (trailing) blanks in some entries) to solve for this problem. You can find the proper names/spellings in the CODMaps.csv file. To full receive full credit, you must write code to solve these issues rather than editing the .csv files. 

#### Explanation:
We plan to answer the question of "which maps are the most likely to win the map vote?" in three phases. In the first phase, we perform EDA and clean the data. We will combine the P1 and P2 tables by assigning each player a 'PlayerID' to prevent loss of data. Then we will explore the attributes 'Map1', 'Map2', and 'Choice'. From this exploration we will determine the best way to approach fixing the spelling and string errors in these attributes. In the second phase, we will specifically focus on working with the 'MapVote' attribute to obtain the difference in votes. This will help us make conclusions about the proportions of times each specific map type was listed as a candidate and earned more votes than the other candidate map. In phase three we will find the proportions of times each specific map was chosen because it earned more votes than the other map. This last phase will answer the question.

#### Phase 1
```{r}
# Joining p1 and p2 tables

# First let's create a new attribute in each data set to indicate the playerID
p1<-p1%>%
  mutate(PlayerID = 'P1')
p2<-p2%>%
  mutate(PlayerID = 'P2')
Combined <- rbind(p1, p2)
```
The code block above has he purpose of combining the tables while creating a surrogate key for each player in order to prevent loss of data when combining the two tables.

```{r}
head(Combined %>% 
  group_by(Map1) %>%
  summarize(count =n()), 10)
```
```{r}
head(Combined %>% 
  group_by(Map2) %>%
  summarize(count =n()),10)
```
```{r}
head(Combined %>% 
  group_by(Choice) %>%
  summarize(count =n()), 10)
```

From these two tables displaying the content in Map1 and Map2, we can see that there are spelling errors and the data is not completely clean. Thus, we must find a way to fix these errors and clean the data. The following code will do this.

```{r}
# Get rid of unnecessary spaces in the data
Combined<- Combined %>% 
  mutate(MapOne = str_trim(Map1), MapTwo = str_trim(Map2), MapChoice = str_trim(Choice))%>%
  select(-Map1, -Map2, -Choice)
```

```{r}
# Take only the first 3 letters of each map name
CODMaps <- maps%>% 
      mutate(ThreeLetters = substr(Name, 1, 3))

# Change the values in Map1, Map2, and Choice to only the first three letters to match with CODMaps
Combined <- Combined%>%
  mutate(Map1 = substr(MapOne, 1, 3), Map2 = substr(MapTwo, 1, 3), Choice = substr(MapChoice, 1, 3))

# Match the letters
Combined$MapOne <- CODMaps$Name[match(Combined$Map1, CODMaps$ThreeLetters)]
Combined$MapTwo <- CODMaps$Name[match(Combined$Map2, CODMaps$ThreeLetters)]
Combined$MapChoice <- CODMaps$Name[match(Combined$Choice, CODMaps$ThreeLetters)]

# Get rid of columns that aren't cleaned
Combined<-Combined%>%
  select(-Map1, -Map2, -Choice)
```
The above code aims to completely fix the spelling and spacing errors in the data for the attributes 'Map1', 'Map2', and 'Choice'. We approached this data cleaning assignment by first getting rid of unnecessary space. Then we moved on to solve the spelling errors. After brainstorming, we came up with the idea to use the first three letters of each string of data in the attributes with the spelling error. We will match these three letters to the first three letters of maps in CODMaps to assign the correct spelling. 

```{r}
head(Combined %>% 
  group_by(MapOne) %>%
  summarize(count =n()),10)
```
```{r}
head(Combined %>% 
  group_by(MapTwo) %>%
  summarize(count =n()), 10)
```
```{r}
head(Combined %>% 
  group_by(MapChoice) %>%
  summarize(count =n()),10)
```
From these three lines of code above, we can see that we successfully fixed the spelling errors and spacing errors within the map1, map2, and choice attributes. We know we fixed these errors in the data because we can see that each of these fixed attributes only has 28 observations when we group by them. According to the CODMaps data set there are only 28 different maps.

```{r}
Combined<- Combined[!is.na(Combined$Result),]
```

```{r}
# Code from MP1 where I analyzed the result variable
Combined <- separate(Combined, col = Result, into=c('teamResult','enemyResult'), sep = "-")
Combined$teamResult <- as.numeric(Combined$teamResult)
Combined$enemyResult <- as.numeric(Combined$enemyResult)
```


```{r}
Combined <- Combined %>%
  mutate(match = case_when(teamResult > enemyResult ~ 'win',
                           teamResult < enemyResult ~ 'loss',
                           teamResult == enemyResult ~ 'draw'))
```
```{r}
Combined <-
  Combined %>%
  mutate(Combwin = ifelse(match == "win", 1, 0))
```
```{r}
colSums(is.na(Combined))
```

#### Phase 2
```{r}
# Calculate the vote difference
calculate_diff <- function(vote) {
  # Split the string into numbers in a list (found online)
  nums <- str_extract_all(vote, "\\d+")[[1]]
  # Subtract only two numbers from the newly created list from 'nums' above
  if (length(nums) == 2) {
    # Finding the difference
    as.numeric(nums[1]) - as.numeric(nums[2])
  } else {
    return(NA)
  }
}
```

```{r}
Combined <- Combined %>%
  mutate(VoteDifference = sapply(MapVote, calculate_diff))

Combined <- Combined %>%
  mutate(MapType = ifelse(VoteDifference == 0, 'Map One', ifelse(MapTwo == MapChoice, 'Map Two', ifelse(MapOne == MapChoice, 'Map One',NA))))%>%
  mutate(Ties = ifelse(VoteDifference == 0, 1, 0))
```

```{r}
MapTypeProportions<-Combined %>% 
  group_by(MapType) %>%
  summarize(count =n(),
            TotalVotes = sum(VoteDifference),
            TotalTies = sum(Ties))
            
MapTypeProportions
```
From this summary and the 'Combined' data frame we can see that there are a total of 839 observations. Let's calculate the overall proportions (doesn't answer the question but gives us more insight).

##### Map1:
```{r}
M1 <- 378
M1_Ties <- 103
M1 <- M1-M1_Ties

M1_Prop <- M1/839
M1_Prop
```
The overall percentage of times listed as a candidate and received more votes than Map2 choice is around 32.78% with a proportion of 275/839
##### Map2:
```{r}
M2 <- 290

M2_Prop <- M2/839
M2_Prop
```
The overall percentage of times listed as a candidate and received more votes than Map1 choice is around 34.56% with a proportion of 290/839.
##### Ties:
```{r}
Ties <- 103

Ties_Prop <- Ties/839
Ties_Prop
```
The overall percentage of times there was a tie in the vote and the Map1 choice was chosen is around 12.27% with a proportion of 103/839.

##### NA's:
```{r}
MapNAs <- 171

MapNAs_Prop <- MapNAs/839
MapNAs_Prop
```
 The overall percentage of times where there where NA values in the candidate cells but a map was still chosen is around 20.38% with a proportion of 171/839

#### Phase 3
```{r}
# Get rid of NAs in data temporarily to find the proportions of the maps chosen
tempCombined <- Combined%>%
  filter(!is.na(VoteDifference) & !is.na(Ties) & !is.na(MapType))%>%
  mutate(IsMap1 = ifelse(MapChoice == MapOne, 1, 0), IsMap2 = ifelse(MapChoice == MapTwo, 1, 0))%>%
  mutate(MapNotChosen = ifelse(MapChoice == MapOne, MapTwo, MapOne))%>%
  mutate(IsNotMap1 = ifelse(MapNotChosen == MapOne, 1, 0), IsNotMap2 = ifelse(MapNotChosen == MapTwo, 1, 0))%>%
  select(PlayerID, MapOne, MapTwo, MapChoice, MapType, VoteDifference, Ties, IsMap1, IsMap2, MapNotChosen, IsNotMap1, IsNotMap2)
```

```{r}
# Create the summary table
MapPicked <- tempCombined%>%
  group_by(MapChoice)%>%
  summarise(TimesSelected = n(),
            TotalVotes = sum(VoteDifference),
            TotalTies = sum(Ties),
            Map1Selected = sum(IsMap1),
            Map2Selected = sum(IsMap2))
head(MapPicked,10)
```



```{r}
MapNotPicked <- tempCombined%>%
  group_by(MapNotChosen)%>%
  summarise(TimesNotSelected = n())
            #TotalVotesNS = sum(VoteDifference),
            #TotalTiesNS = sum(Ties),
            #Map1NotSelected = sum(IsNotMap1),
            #Map2NotSelected = sum(IsNotMap2))
MapNotPicked
```
```{r}
combined_maps <- left_join(MapPicked, MapNotPicked, by = c("MapChoice" = "MapNotChosen"))

combined_maps <- combined_maps %>%
  mutate(TotalCandidates = (TimesSelected + TimesNotSelected)-TotalTies)

```
##### Interpretting the tables and code above
All of the code above is meant to find the total times a map was selected and was not selected when it was a candidate in the map selection/voting of the game. This will help us determine the proportions. In the 'MapPicked' table you can see each broken down statistic of whether the chosen map was of Map1 or Map2 type, the total votes for the chosen map, and the ties.
##### Finding the proportions and visualizing them
```{r}
# Calculate the proportions for every map
map_selected <- (combined_maps$TimesSelected)-(combined_maps$TotalTies)
map_candidates <- combined_maps$TotalCandidates
combined_maps <- combined_maps%>%
  mutate(map_proportions = (map_selected / map_candidates))%>%
  arrange(desc(map_proportions))%>%
  select(MapChoice, map_proportions)

```

```{r}
# Visualize the data
ggplot(data = combined_maps, mapping = aes(x = MapChoice, y = map_proportions, fill = MapChoice))+
  geom_bar(stat = 'Identity') +
  coord_flip() +
  labs(title = 'Map Selection Proportion for Each Map', x = 'Map', y = 'Proportion of Being Selected') +
  theme_minimal()
```
```{r}
head(combined_maps, 5)
```
##### Answering the Question
According to our data, the 5 maps that are most likely to win the map vote (without the occurrence of a tie in votes) are Nuketown '84, Raid, Crossroads Strike, Diesel, and Standoff.


### Part 2
```{r}
# Cleaning GameType variable
p1 <- p1 %>%
  mutate(GameType = case_when(
    grepl("HC", GameType) & grepl("TDM", GameType) ~ "TDM",
    grepl("HC", GameType) & grepl("Hardpoint", GameType) ~ "Hardpoint",
    TRUE ~ GameType
  ))

# EDA - Distribution of TotalXP and Score
p1 %>%
  ggplot(aes(x = TotalXP, y = Score, color = GameType)) +
  geom_point() +
  labs(title = "Distribution of TotalXP and Score by GameType",
       x = "TotalXP", y = "Score")

# EDA - Boxplot to compare TotalXP by GameType
p1 %>%
  ggplot(aes(x = GameType, y = TotalXP)) +
  geom_boxplot() +
  labs(title = "Boxplot of TotalXP by GameType",
       x = "GameType", y = "TotalXP")

# Building a linear regression model
model <- lm(TotalXP ~ Score + GameType, data = p1)

# Summary of the model
summary(model)

# Predict TotalXP using the model
predicted_totalxp <- predict(model, newdata = p1)

# Compare predicted_totalxp with the actual TotalXP
comparison_df <- data.frame(Actual = p1$TotalXP, Predicted = predicted_totalxp)

# Cleaning GameType variable for p2
p2 <- p2 %>%
  mutate(GameType = case_when(
    grepl("HC", GameType) & grepl("TDM", GameType) ~ "TDM",
    grepl("HC", GameType) & grepl("Hardpoint", GameType) ~ "Hardpoint",
    TRUE ~ GameType
  ))

# EDA - Distribution of TotalXP and Score for p2
p2 %>%
  ggplot(aes(x = TotalXP, y = Score, color = GameType)) +
  geom_point() +
  labs(title = "Distribution of TotalXP and Score by GameType (p2)",
       x = "TotalXP", y = "Score")

# EDA - Boxplot to compare TotalXP by GameType for p2
p2 %>%
  ggplot(aes(x = GameType, y = TotalXP)) +
  geom_boxplot() +
  labs(title = "Boxplot of TotalXP by GameType (p2)",
       x = "GameType", y = "TotalXP")

# Building a linear regression model for p2
model_p2 <- lm(TotalXP ~ Score + GameType, data = p2)

# Summary of the model for p2
summary(model_p2)

# Predict TotalXP using the model for p2
predicted_totalxp_p2 <- predict(model_p2, newdata = p2)

# Compare predicted_totalxp_p2 with the actual TotalXP for p2
comparison_df_p2 <- data.frame(Actual = p2$TotalXP, Predicted = predicted_totalxp_p2)
head(comparison_df_p2, 10)
```
TDM and hardpoint had the most variation but also more data. It seems that those two had the most extremes pulling the score mean higher and due to this making the score likely to be higher in these game modes.The least likely is HC- killed confirmed. If a player wanted a game mode to most likely increase his score, the player should consider playing TDM and hardpoint.

### Part 3: What variables are significant in determining the outcome of a given Damage, Eliminations, Deaths, Score, TotalXP, PrimaryWeapon, XPType, and FullPartial, and GameType?


#### Random Forest:
```{r}
#Perform an 80/20 training/validation split
set.seed(123)
trainInd <- sample(1:nrow(Combined), floor(0.8 * nrow(Combined)))
set.seed(NULL)

Train <- Combined[trainInd, ]
Validation <- Combined[-trainInd, ]
```


```{r}
#Build model using a seed of 123
set.seed(123)
rfModel <- randomForest(as.factor(Combwin) ~ Damage+ Eliminations+ Deaths+ Score+ TotalXP+ PrimaryWeapon+ XPType+ FullPartial + GameType, 
                        data = Train, 
                        ntree = 500, 
                        mtry = 3,
                        importance = TRUE)
set.seed(NULL)

#Obtain predicted probabilities - not needed for confusion matrix but included to show we all get same probabilities when using the same seed
predProb <- predict(rfModel, newdata = Validation, type = "prob")
head(predProb)

#To create the confusion matrix, we need to determine which class (No or Yes) is more likely. Although we could define a threshold and compare probabilities as we have done in the past, things are more challenging if y has more than 2 classes. So, let R pick for us.
predSurv <- predict(rfModel, newdata = Validation, type = "response")
  
#Create confusion matrix
table(predSurv, Validation$Combwin)

#Calculate accuracy
mean(predSurv == Validation$Combwin)
```

```{r}
rfModel$importance
```

- Judging by the information given by the importance table, Deaths, TotalXP, and Eliminations are the top three significant variables judged by the avergae decrease in the Gini Index and the Mean Decrease in Accuracy. This pertains the model generated by the Random Forest Model.

#### Forward Selection

```{r}
#Build Intercept Only Model. NOTE: ~ 1 tells R that you only want an intercept
int_only_model <- glm(Combwin ~ 1, data = Train)

#Build model with all potential regressors. 
#In code below, SurvivedNum ~ . tells R to use all columns in dataset to predict SurvivedNum
#SurvivedNum ~ . -Survived tells R to use all columns except Survived to predict SurvivedNum
full_model <- glm(Combwin ~ Damage+ Eliminations+ Deaths+ Score+ TotalXP+ PrimaryWeapon+ XPType+ FullPartial + GameType, data = Train)

#Perform forward elimination
#Have R do it all
stats::step(object = int_only_model, 
            scope = list(lower = int_only_model, upper = full_model),
            data = Train,
            direction = "forward")
```

- Using forward selection, we can see Deaths, TotalXP, and XPType are the top three picks for the variables, and then FullPartial, GameType, and Score are the other options. As a common denominator between RandomForest and Forward Selection is the TotalXP being chosen as one of the most significant variables.

#### Poisson Regression Model

```{r}
prmodel <- glm(Combwin ~ Damage+ Eliminations+ Deaths+ Score+ TotalXP+ PrimaryWeapon+ XPType+ FullPartial + GameType, data = Train, family = poisson)
```

```{r}
summary(prmodel)
```

- We are using Poisson Regression as we aim to find the variables that allow a win to occur most frequently. Using the statistical summary, poisson regression shows Kill Confirmed and Domination are the most influential in determining a the chances of a win. Oddly enough, our significant variables in our other methods did not appear to be influential.
- Judging from this we will choose our random forest model to determine the outcome of the win.
