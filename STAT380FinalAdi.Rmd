---
title: "FinalProjectAdithya"
author: "Adithya Sadagopan"
date: "2023-12-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Part 3

## Front Matter
```{r  message=FALSE, warning=FALSE}
library(tidyverse)
library(randomForest)
```

### Read in Data
```{r}
maps <- read.csv(file = "data/CODMaps.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL)
p1 <- read.csv(file = "data/CODGames_p1_380.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL,
                 na.strings = c("", "NA"))
p2 <- read.csv(file = "data/CODGames_p2_380.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL,
                 na.strings = c("", "NA"))
gmodes <- read.csv(file = "data/CODGameModes.csv",
                 sep = ",",
                 header = TRUE,
                 row.names = NULL)
```

```{r}
# First let's create a new attribute in each data set to indicate the playerID
p1<-p1%>%
  mutate(PlayerID = 'P1')
p2<-p2%>%
  mutate(PlayerID = 'P2')
Combined <- rbind(p1, p2)
```

```{r}
# Get rid of unnecessary spaces in the data
Combined<- Combined %>% 
  mutate(MapOne = str_trim(Map1), MapTwo = str_trim(Map2), MapChoice = str_trim(Choice))%>%
  select(-Map1, -Map2, -Choice)
```

```{r}
# Take only the first 3 letters of each map name
CODMaps <- maps%>% 
      mutate(ThreeLetters = substr(Name, 1, 3))

# Change the values in Map1, Map2, and Choice to only the first three letters to match with CODMaps
Combined <- Combined%>%
  mutate(Map1 = substr(MapOne, 1, 3), Map2 = substr(MapTwo, 1, 3), Choice = substr(MapChoice, 1, 3))

# Match the letters
Combined$MapOne <- CODMaps$Name[match(Combined$Map1, CODMaps$ThreeLetters)]
Combined$MapTwo <- CODMaps$Name[match(Combined$Map2, CODMaps$ThreeLetters)]
Combined$MapChoice <- CODMaps$Name[match(Combined$Choice, CODMaps$ThreeLetters)]

# Get rid of columns that aren't cleaned
Combined<-Combined%>%
  select(-Map1, -Map2, -Choice)
```

```{r}
Combined<- Combined[!is.na(Combined$Result),]
```

```{r}
# Code from MP1 where I analyzed the result variable
Combined <- separate(Combined, col = Result, into=c('teamResult','enemyResult'), sep = "-")
Combined$teamResult <- as.numeric(Combined$teamResult)
Combined$enemyResult <- as.numeric(Combined$enemyResult)
```


```{r}
Combined <- Combined %>%
  mutate(match = case_when(teamResult > enemyResult ~ 'win',
                           teamResult < enemyResult ~ 'loss',
                           teamResult == enemyResult ~ 'draw'))
```
```{r}
Combined <-
  Combined %>%
  mutate(Combwin = ifelse(match == "win", 1, 0))
```
```{r}
colSums(is.na(Combined))
```



## Part 3: What variables are significant in determining the outcome of a given Damage, Eliminations, Deaths, Score, TotalXP, PrimaryWeapon, XPType, and FullPartial, and GameType?


### Random Forest:
```{r}
#Perform an 80/20 training/validation split
set.seed(123)
trainInd <- sample(1:nrow(Combined), floor(0.8 * nrow(Combined)))
set.seed(NULL)

Train <- Combined[trainInd, ]
Validation <- Combined[-trainInd, ]
```


```{r}
#Build model using a seed of 123
set.seed(123)
rfModel <- randomForest(as.factor(Combwin) ~ Damage+ Eliminations+ Deaths+ Score+ TotalXP+ PrimaryWeapon+ XPType+ FullPartial + GameType, 
                        data = Train, 
                        ntree = 500, 
                        mtry = 3,
                        importance = TRUE)
set.seed(NULL)

#Obtain predicted probabilities - not needed for confusion matrix but included to show we all get same probabilities when using the same seed
predProb <- predict(rfModel, newdata = Validation, type = "prob")
head(predProb)

#To create the confusion matrix, we need to determine which class (No or Yes) is more likely. Although we could define a threshold and compare probabilities as we have done in the past, things are more challenging if y has more than 2 classes. So, let R pick for us.
predSurv <- predict(rfModel, newdata = Validation, type = "response")
  
#Create confusion matrix
table(predSurv, Validation$Combwin)

#Calculate accuracy
mean(predSurv == Validation$Combwin)
```

```{r}
rfModel$importance
```

- Judging by the information given by the importance table, Deaths, TotalXP, and Eliminations are the top three significant variables judged by the avergae decrease in the Gini Index and the Mean Decrease in Accuracy. This pertains the model generated by the Random Forest Model.

### Forward Selection

```{r}
#Build Intercept Only Model. NOTE: ~ 1 tells R that you only want an intercept
int_only_model <- glm(Combwin ~ 1, data = Train)

#Build model with all potential regressors. 
#In code below, SurvivedNum ~ . tells R to use all columns in dataset to predict SurvivedNum
#SurvivedNum ~ . -Survived tells R to use all columns except Survived to predict SurvivedNum
full_model <- glm(Combwin ~ Damage+ Eliminations+ Deaths+ Score+ TotalXP+ PrimaryWeapon+ XPType+ FullPartial + GameType, data = Train)

#Perform forward elimination
#Have R do it all
stats::step(object = int_only_model, 
            scope = list(lower = int_only_model, upper = full_model),
            data = Train,
            direction = "forward")
```

- Using forward selection, we can see Deaths, TotalXP, and XPType are the top three picks for the variables, and then FullPartial, GameType, and Score are the other options. As a common denominator between RandomForest and Forward Selection is the TotalXP being chosen as one of the most significant variables.

### Poisson Regression Model

```{r}
prmodel <- glm(Combwin ~ Damage+ Eliminations+ Deaths+ Score+ TotalXP+ PrimaryWeapon+ XPType+ FullPartial + GameType, data = Train, family = poisson)
```

```{r}
summary(prmodel)
```

- We are using Poisson Regression as we aim to find the variables that allow a win to occur most frequently. Using the statistical summary, poisson regression shows Kill Confirmed and Domination are the most influential in determining a the chances of a win. Oddly enough, our significant variables in our other methods did not appear to be influential.


